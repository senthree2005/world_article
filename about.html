<!doctype html>
<html>
    <head>
        <meta charset=utf-8>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="./assets/style/main.css">
        <link rel="icon" href="./assets/images/favicon.png" type="image/png">
        <title></title>
    </head>
    <body>
        <div id="container">
            <header>
                <nav id="nav"></nav>
                <h1>SDG's</h1>
                <hr>
            </header>

            <main>
                <!------------------------------------------------>
                <!-- This is where you place your bio! -->
                 <a href = "#summary" ><h2 style="text-align: center;">Summary</h2></a>
                 <ul>
                    <li><h2>No Poverty (SDG1)</h2><sub><p>HelioHound: AI-Powered Quadruped Robot with Dual Manipulator Arms for Disaster Response and Livelihood Protection in Vulnerable Communities</sub></li>
                    <li><h2>Zero hunger (SDG 2)</h2><sub><p>HelioHound: AI-Powered Quadruped Robot with Dual Manipulator Arms for Disaster Response and Livelihood Protection in Vulnerable Communities</sub></li>
                    <li><h2>Good health and well-being (SDG 3)</h2><sub><p>M-Bot: An Autonomous Robotic System for Non-Invasive Prenatal Imaging and Maternal Health Monitoring </sub></li>
                    <li><h2>Quality education (SDG 4)</h2><sub><p>RoboVox: A Soft-Robotics and Resonant-Cavity-Based Mechanical Speech Robot for Interactive STEM and Phonetics Education </sub></li>
                    <li><h2>Gender equality (SDG 5)</h2><sub><p>M-Bot: An Autonomous Robotic System for Non-Invasive Prenatal Imaging and Maternal Health Monitoring</sub></li>
                    <li><h2>Clean water and sanitation (SDG 6)</h2><sub><p>HEXATERRA: Autonomous Parallel Robot-assisted Mechanical Weeding System for Sustainable Crop Production and Water Conservation</sub></li>
                    <li><h2>Affordable and clean energy (SDG 7)</h2><sub><p>METHA-DRONE: Autonomous Aerial Methane Recovery and Distributed Renewable Energy Integration System for Sustainable Power Applications</sub></li>
                    <li><h2>Decent work and economic growth (SDG 8)</h2><sub><p>HelioHound: AI-Powered Quadruped Robot with Dual Manipulator Arms for Disaster Response and Livelihood Protection in Vulnerable Communities</sub></li>
                    <li><h2>Industry, innovation and infrastructure (SDG 9)</h2><sub><p> M-Bot: An Autonomous Robotic System for Non-Invasive Prenatal Imaging and Maternal Health Monitoring</sub></li>
                    <li><h2>Reduced inequalities (SDG 10)</h2><sub><p> M-Bot: An Autonomous Robotic System for Non-Invasive Prenatal Imaging and Maternal Health Monitoring  </sub></li>
                    <li><h2>Sustainable cities and communities (SDG 11)</h2><sub><p> BuoyBot: AI-Integrated Robotic System for Flood Mitigation and Humanitarian Response  </sub></li>
                    <li><h2>Responsible consumption and production (SDG 12)</h2><sub><p>HEXATERRA: Autonomous Parallel Robot-assisted Mechanical Weeding System for Sustainable Crop Production and Water Conservation</sub></li>
                    <li><h2>Climate action (SDG 13)</h2><sub><p>BuoyBot: AI-Integrated Robotic System for Flood Mitigation and Humanitarian Response</sub></li>
                    <li><h2>Life below water (SDG 14)</h2><sub><p>CHRONOS: Smart Machine Learning-Integrated Robotic Systemfor Marine Dead Zone Remediation Through Chemosynthetic Bioprocessing</sub></li>
                    <li><h2>Life on land (SDG 15)</h2><sub><p>TerraGuard: An Autonomous Swarm Robotics System for Biodiversity Monitoring, Ecosystem Restoration, and Sustainable Land Management</sub></li>
                    <li><h2>Peace, justice, and strong institutions (SDG 16)</h2><sub><p>NeuRing-AERIS System: A Smart Wearable-Drone Approach to Children`s Security and Safety Monitoring</sub></li>
                    <li><h2>Partnerships for the goals (SDG 17)</h2><sub><p>M-Bot: An Autonomous Robotic System for Non-Invasive Prenatal Imaging and Maternal Health Monitoring</sub></li>
                 </ul>
                

                 <div id ="summary">
                    <h2 style="text-align: center;">Summary</h2>
                    <label for="sdg_num">Pick SDG Summary:</label>
                    <select id = "sdg" name = "sdg" onchange = "changeParagraph()">
                        <option value = "" selected></option>
                        <option value = "heliohound">SDG 1/8-HelioHound</option>
                        <option value = "MBOT">SDG 3/5/9/10/17-MBOT</option>
                        <option value = "Neuring">SDG 16-Neuring</option>
                        <option value = "Chronos">SDG 14-Chronos</option>
                        <option value = "METHA-DRONE">SDG 7-METHA-DRONE</option>
                        <option value = "HEXATERRA">SDG 2/6/12-HEXATERRA</option>
                        <option value = "BUOYBOT">SDG 11/13-BUOYBOT</option>
                        <option value = "TERRAGUARD">SDG 15/13-TERRAGUARD</option>
                        <option value = "ROBOVOX">SDG 4-ROBOVOX</option>

                    </select>
                    <p id="result">Selected Summary Will Appear Here.</p>
                 </div>







            </main>
            <hr id="seperator">
            <footer id="footer"></footer>
        </div>
        <!-- Let's link our javascript-->
        <script>
            function changeParagraph() {
                const summaries = ["HelioHound is a lifesaving robotic companion that ensures the rapid detection and rescue of individuals affected by natural and human-induced disasters, while simultaneously protecting the livelihoods of vulnerable communities, hitting SDG 1 (No Poverty) and SDG 8 (Decent Work and Economic Growth). HelioHound will offer a solar-powered quadruped robotic solution that will autonomously navigate collapsed structures, unstable terrains, flooded areas, and blocked pathways to locate trapped survivors based on real-time environmental data and adapt to unpredictable disaster conditions. This robotic solution will improve disaster response services by speeding up survivor detection and reducing physical risks to human rescuers, thereby preserving the workforce and preventing disaster-induced economic decline. For safety and risk management, HelioHound will offer an automated adaptive stabilization mode. When the data of the various integrated motion sensors, thermal imagers, gas detectors, and audio sensors detect instability or hazardous conditions, the on-board computer triggers the automated balance correction system to keep the robot operational and prevent mission failure, at the same time, HelioHound will recognize survivor indicators such as motion, heat signatures, or sound through AI-assisted pattern recognition. The operating duration of the robotic system is approximately 8–12 hours under solar-rechargeable conditions, depending on the recommendation of the incident commander regarding the search parameters for the affected area. This robotic system powered by artificial intelligence can be used in urban search and rescue, post-disaster reconnaissance, and humanitarian assistance operations. HelioHound will be instrumental in identifying different ways in utilizing AI in disaster risk reduction and sustainable community development.",
                    "M-Bot is an autonomous robotic system that ensures safe, accessible, and non-invasive prenatal imaging and maternal health monitoring for expectant mothers worldwide, promoting good health and well-being while reducing inequalities in maternal healthcare access, hitting SDG 3 (Good Health and Well-Being), SDG 5 (Gender Equality), SDG 9 (Industry, Innovation, and Infrastructure), SDG 10 (Reduced Inequalities), and SDG 17 (Partnerships for the Goals). M-Bot will offer a contactless robotic solution that will perform AI-assisted prenatal ultrasound imaging and maternal vital signs monitoring based on real-time physiological data and adapt to diverse clinical environments from urban hospitals to remote rural clinics. This robotic solution will improve maternal healthcare delivery by enabling early detection of pregnancy complications, reducing dependence on specialized sonographers, and providing hygienic, non-contact diagnostic capabilities in infection-sensitive settings. For safety and risk management, M-Bot will offer an automated patient-safe positioning mode. When the data of the various integrated proximity sensors, force feedback mechanisms, and motion detectors indicate potential patient discomfort or unsafe positioning, the on-board computer triggers the autonomous repositioning protocol to maintain optimal imaging distance and prevent physical contact, at the same time, M-Bot will continuously analyze fetal parameters and maternal vitals through its AI-powered imaging core. The operating duration of the robotic system is approximately 4–6 hours on a single charge, depending on the recommendation of the attending obstetrician regarding the diagnostic requirements for each patient. This robotic system powered by artificial intelligence can be used in prenatal care facilities, community health centers, mobile health units, and telemedicine-enabled remote diagnostics. M-Bot will be instrumental in identifying different ways in utilizing AI in maternal and child health, particularly in underserved and resource-limited settings.",
                    "NeuRing-AERIS System is an integrated wearable-drone framework that ensures the continuous security, safety, and real-time monitoring of children while providing peace of mind to parents and caregivers, promoting peaceful and inclusive societies through technology-enabled child protection, hitting SDG 16 (Peace, Justice, and Strong Institutions). NeuRing–AERIS System will offer a two-component robotic solution consisting of the Neuroband Ring wearable and the AERIS autonomous drone that will monitor a child's vital signs, emotional state, and location in real-time based on physiological and environmental data and adapt to both urban and rural settings with or without smartphone coverage. This robotic solution will improve child protection services by enabling immediate distress detection, autonomous aerial deployment for situational awareness, and rapid notification of authorities and caregivers when threats are detected. For safety and risk management, NeuRing–AERIS System will offer an automated emergency response mode. When the data of the various integrated EMG, EDA, PPG, accelerometer, and gyro sensors detect irregular heart rate, emotional stress, sudden falls, violent movements, or unexpected ring removal, the onboard computer triggers the autonomous deployment of the AERIS drone to the child's GPS location to provide real-time video and audio surveillance, at the same time, the system will send immediate alerts to designated caregivers and authorities. The operating duration of the Neuroband Ring is approximately 48–72 hours on a single charge, depending on the recommendation of parents or guardians regarding the monitoring requirements for each child. This robotic system powered by artificial intelligence can be used in schools, playgrounds, and high-risk areas where child abduction or accidents are prevalent. NeuRing–AERIS System will be instrumental in identifying different ways in utilizing AI in child protection and community safety.",
                    "CHRONOS is an ocean restoration companion that ensures the rehabilitation of marine dead zones and promotes the sustainability of underwater ecosystems, addressing Sustainable Development Goal (SDG) No. 14. CHRONOS will offer a full-cycle robotic solution that will remediate and rehabilitate hypoxic and anoxic marine environments based on the chemical needs of the target zone and adapt to dynamic oceanic conditions and movements. This robotic solution will improve ocean health services by accelerating the recovery of oxygen-depleted areas and supporting long-term ecosystem stability. For safety and risk management, CHRONOS is equipped with a robust hazard response system. When integrated sensors detect conditions such as a hull breach, the presence of hazardous chemicals, or an imminent collision, the onboard computer will trigger predefined failsafe protocols, including emergency surfacing and process shutdown, to protect both the system and the surrounding environment. The operating cycle of the robotic system is approximately 30 days, depending on the recommendation of marine scientists regarding the treatment duration for the target area. This robotic system, powered by solar energy, artificial intelligence, and machine learning, can be applied to marine dead zone rehabilitation and blue carbon farming practices. CHRONOS will be a supporting platform in identifying innovative applications of robotics in ocean conservation.",
                    "METHA-DRONE is an autonomous aerial robotic swarm that ensures the capture of atmospheric methane emissions and their conversion into usable electricity, promoting affordable and clean energy access while mitigating greenhouse gas emissions, hitting SDG 7 (Affordable and Clean Energy). METHA-DRONE will offer a swarm-based robotic solution consisting of multiple coordinated flying robots that will detect methane concentration hotspots using laser sensors, capture methane through onboard selective absorption membranes, and convert it into electricity using micro solid oxide fuel cells based on real-time gas concentration data and adapt to diverse emission environments from landfills to livestock farms. For safety and risk management, METHA-DRONE will offer an automated emergency landing and swarm coordination mode. When integrated gas sensors detect unsafe operating conditions, the onboard computer triggers autonomous return-to-base protocols while the swarm AI dynamically redistributes tasks among remaining drones. The operating duration of each drone is approximately 30–45 minutes of continuous flight, depending on methane concentration levels. This robotic system powered by artificial intelligence can be used in landfills, oil and gas fields, livestock farms, and remote rural communities. METHA-DRONE will be instrumental in utilizing AI for atmospheric methane harvesting and distributed energy generation.",
                    "HEXATERRA is an autonomous parallel robot-assisted mechanical weeding system that ensures sustainable crop production and water conservation while eliminating herbicide use, promoting zero hunger, clean water, and responsible consumption, hitting SDG 2 (Zero Hunger), SDG 6 (Clean Water and Sanitation), and SDG 12 (Responsible Consumption and Production). HEXATERRA will offer a six-degree-of-freedom parallel robotic solution that will perform plant-specific mechanical weeding, soil aeration, and precision irrigation based on real-time plant electrical signals and soil moisture data and adapt to diverse crop environments from small farms to large agricultural operations. This robotic solution will improve agricultural sustainability by removing weeds without chemicals, improving water infiltration through micro-aeration, and reducing water waste through sub-surface drip irrigation. For safety and risk management, HEXATERRA will offer an automated adaptive stabilization mode. When the data of the various integrated motion sensors, ground-penetrating radar, and plant electrical signal sensors detect uneven terrain or unstable operating conditions, the onboard computer triggers the adaptive stabilization system to maintain balance and prevent crop damage, at the same time, HEXATERRA will detect early-stage plant diseases through its living sensor array. The operating duration of the robotic system is approximately 6–8 hours on a single charge, depending on the recommendation of the farmer regarding the field size and weeding requirements for each crop. This robotic system powered by artificial intelligence can be used in row crops, orchards, vineyards, and vegetable farms. HEXATERRA will be instrumental in identifying different ways in utilizing AI in precision agriculture and sustainable food production.",
                    "BuoyBot is an AI-integrated robotic system that ensures rapid, autonomous, and effective flood mitigation and humanitarian response in disaster-affected communities, promoting safe, resilient, and sustainable cities and human settlements, hitting SDG 11 (Sustainable Cities and Communities). BuoyBot will offer a twin-hull autonomous surface vehicle with self-righting capability that will navigate flooded streets, detect trapped survivors using AI-powered human detection, thermal imaging, and sonar sensors, and provide real-time GPS location data to rescue teams based on environmental conditions and adapt to strong currents, poor visibility, and floating debris common in flood zones. This robotic solution will improve disaster response operations by continuously patrolling flooded areas, detecting survivors faster than human crews in cluttered conditions, and serving as a communication hub for stranded individuals and emergency teams. For safety and risk management, BuoyBot will offer an automated self-righting stabilization mode. When the data of the various integrated gyroscopes, accelerometers, and water current sensors detect potential capsizing or instability, the onboard computer triggers the autonomous self-righting mechanism to restore balance and prevent mission failure, at the same time, BuoyBot will continue transmitting survivor locations through its swarm network. The operating duration of the robotic system is approximately 8–10 hours powered by solar panels and modular batteries, depending on the recommendation of incident commanders regarding the search area coverage for each mission. This robotic system powered by artificial intelligence can be used in flood-prone cities, coastal communities, and informal settlements during typhoons and monsoon seasons. BuoyBot will be instrumental in identifying different ways in utilizing AI in sustainable disaster response and resilient infrastructure development.",
                    "TerraGuard is an autonomous swarm robotics system that ensures the restoration of degraded ecosystems, protection of endangered species, and continuous monitoring of land health, promoting life on land and climate action through intelligent, coordinated robotic intervention, hitting SDG 15 (Life on Land) and SDG 13 (Climate Action). TerraGuard will offer a multi-robot swarm solution consisting of ground robots, micro-drones, and sensor-equipped aerial units that will perform reforestation, soil rehabilitation, biodiversity tracking, invasive species control, and wildfire prevention based on real-time environmental data and adapt to changing conditions such as forest regrowth, animal movement, or natural disasters. This robotic solution will improve ecosystem management by actively restoring degraded lands rather than merely monitoring them, enabling precise seed dispersal, targeted soil enhancement, and early threat detection. For safety and risk management, TerraGuard will offer an automated swarm coordination and collision avoidance mode. When the data of the various integrated heat sensors, smoke detectors, acoustic monitors, and camera systems detect wildfire risks, poaching activity, or environmental hazards, the onboard AI triggers autonomous deployment of fire-retardant capsules or alerts conservation authorities, at the same time, the swarm will dynamically redistribute monitoring tasks among remaining units. The operating duration of each robot varies from 30 minutes to 8 hours depending on unit type and mission parameters. This robotic system powered by artificial intelligence can be used in forests, national parks, wetlands, and degraded agricultural lands. TerraGuard will be instrumental in identifying different ways in utilizing AI in ecosystem restoration and biodiversity conservation.",
                    "RoboVox is a soft-robotics and resonant-cavity-based mechanical speech robot that ensures interactive, tangible, and inclusive learning of phonetics, speech production, and STEM concepts for students of all ages and abilities, promoting quality education through hands-on experimentation and multi-sensory engagement, hitting SDG 4 (Quality Education). RoboVox will offer a transparent, modular robotic solution consisting of electromechanical vocal cords, a soft robotic tongue, articulated lips, and resonant cavities that will mimic human speech production mechanically based on real-time AI analysis of student pronunciation and adapt to individual learning needs and abilities across multiple languages and accents. This robotic solution will improve speech and language education by making abstract phonetic concepts visible and tangible, enabling students to see, hear, and feel how sounds are physically produced rather than relying on digital speakers or pre-recorded audio. For safety and risk management, RoboVox will offer an automated gentle interaction mode. When the data of the various integrated proximity sensors and force feedback mechanisms detect potential physical interaction risks, the onboard computer triggers the automated movement limitation protocol to prevent pinching or excessive force, at the same time, RoboVox will adjust its vocal demonstrations based on student engagement levels through AI analysis. The operating duration of the robotic system is approximately 2–3 hours on a single charge, depending on the recommendation of the educator regarding the session duration for each student. This robotic system powered by artificial intelligence can be used in language learning classrooms, speech therapy centers, STEM laboratories, and inclusive education programs. RoboVox will be instrumental in identifying different ways in utilizing AI in phonetic education and assistive learning technology.",

                ]
                const selectElement = document.getElementById("sdg");
                const paragraphElement = document.getElementById("result");
                const selectedValue = selectElement.value;

                switch (selectedValue) {
                    case 'heliohound':
                        paragraphElement.innerHTML = summaries[0];
                        break;
                    case 'MBOT':
                        paragraphElement.innerHTML = summaries[1];
                        break;
                    case 'Neuring':
                        paragraphElement.innerHTML = summaries[2];
                        break;
                    case 'Chronos':
                        paragraphElement.innerHTML = summaries[3];
                        break;
                    case 'METHA-DRONE':
                        paragraphElement.innerHTML = summaries[4];
                        break;
                    case 'HEXATERRA':
                        paragraphElement.innerHTML = summaries[5];
                        break;
                    case 'BUOYBOT':
                        paragraphElement.innerHTML = summaries[6];
                        break;
                    case 'TERRAGUARD':
                        paragraphElement.innerHTML = summaries[7];
                        break;
                    case 'ROBOVOX':
                        paragraphElement.innerHTML = summaries[8];
                        break;
                    default:
                        paragraphElement.innerHTML = "Select An SDG";
                }
            }
        </script>
        <script src="./deadlogs.js" charset="utf-8"></script>
        <script src="./scripts/posts.js" charset="utf-8"></script>
        <script src="./scripts/console.js" charset="utf-8"></script>
    </body>
</html>
