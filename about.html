<!doctype html>
<html>
    <head>
        <meta charset=utf-8>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="./assets/style/main.css">
        <link rel="icon" href="./assets/images/favicon.png" type="image/png">
        <title></title>
    </head>
    <body>
        <div id="container">
            <header>
                <nav id="nav"></nav>
                <h1>Sustainable Development Goals</h1>
                <hr>
            </header>

            <main>
                <!------------------------------------------------>
                <!-- This is where you place your bio! -->
                 <a href = "#summary" ><h2 style="text-align: center;">Info</h2></a>
                 <ul>
                    <li><h2>No Poverty</h2><sub><p>HelioHound: AI-Powered Quadruped Robot with Dual Manipulator Arms for Disaster Response and Livelihood Protection in Vulnerable Communities</sub></li>
                    <li><h2>Zero hunger</h2><sub><p>HelioHound: AI-Powered Quadruped Robot with Dual Manipulator Arms for Disaster Response and Livelihood Protection in Vulnerable Communities</sub></li>
                    <li><h2>Good health and well-being</h2><sub><p>M-Bot: An Autonomous Robotic System for Non-Invasive Prenatal Imaging and Maternal Health Monitoring </sub></li>
                    <li><h2>Quality education</h2><sub><p>RoboVox: A Soft-Robotics and Resonant-Cavity-Based Mechanical Speech Robot for Interactive STEM and Phonetics Education </sub></li>
                    <li><h2>Gender equality</h2><sub><p>M-Bot: An Autonomous Robotic System for Non-Invasive Prenatal Imaging and Maternal Health Monitoring</sub></li>
                    <li><h2>Clean water and sanitation</h2><sub><p>HEXATERRA: Autonomous Parallel Robot-assisted Mechanical Weeding System for Sustainable Crop Production and Water Conservation</sub></li>
                    <li><h2>Affordable and clean energy</h2><sub><p>METHA-DRONE: Autonomous Aerial Methane Recovery and Distributed Renewable Energy Integration System for Sustainable Power Applications</sub></li>
                    <li><h2>Decent work and economic growth</h2><sub><p>HelioHound: AI-Powered Quadruped Robot with Dual Manipulator Arms for Disaster Response and Livelihood Protection in Vulnerable Communities</sub></li>
                    <li><h2>Industry, innovation and infrastructure</h2><sub><p> M-Bot: An Autonomous Robotic System for Non-Invasive Prenatal Imaging and Maternal Health Monitoring</sub></li>
                    <li><h2>Reduced inequalities</h2><sub><p> M-Bot: An Autonomous Robotic System for Non-Invasive Prenatal Imaging and Maternal Health Monitoring  </sub></li>
                    <li><h2>Sustainable cities and communities</h2><sub><p> BuoyBot: AI-Integrated Robotic System for Flood Mitigation and Humanitarian Response  </sub></li>
                    <li><h2>Responsible consumption and production</h2><sub><p>HEXATERRA: Autonomous Parallel Robot-assisted Mechanical Weeding System for Sustainable Crop Production and Water Conservation</sub></li>
                    <li><h2>Climate action</h2><sub><p>BuoyBot: AI-Integrated Robotic System for Flood Mitigation and Humanitarian Response</sub></li>
                    <li><h2>Life below water</h2><sub><p>CHRONOS: Smart Machine Learning-Integrated Robotic Systemfor Marine Dead Zone Remediation Through Chemosynthetic Bioprocessing</sub></li>
                    <li><h2>Life on land</h2><sub><p>TerraGuard: An Autonomous Swarm Robotics System for Biodiversity Monitoring, Ecosystem Restoration, and Sustainable Land Management</sub></li>
                    <li><h2>Peace, justice, and strong institutions</h2><sub><p>NeuRing-AERIS System: A Smart Wearable-Drone Approach to Children`s Security and Safety Monitoring</sub></li>
                    <li><h2>Partnerships for the goals</h2><sub><p>M-Bot: An Autonomous Robotic System for Non-Invasive Prenatal Imaging and Maternal Health Monitoring</sub></li>
                 </ul>
                

                 <div id ="summary">
                    <h2 style="text-align: center;">Info</h2>
                    <label for="sdg_num">Pick SDG Info:</label>
                    <select id = "sdg" name = "sdg" onchange="changeParagraph()" style="padding: 10px 15px; font-size: 16px; border: 2px solid #ccc; border-radius: 5px; background-color: #f9f9f9; color: #333; cursor: pointer;">
                        <option value = "heliohound">1/8-HelioHound</option>
                        <option value = "MBOT">3/5/9/10/17-MBOT</option>
                        <option value = "Neuring">16-Neuring</option>
                        <option value = "Chronos">14-Chronos</option>
                        <option value = "METHA-DRONE">7-METHA-DRONE</option>
                        <option value = "HEXATERRA">2/6/12-HEXATERRA</option>
                        <option value = "BUOYBOT">11/13-BUOYBOT</option>
                        <option value = "TERRAGUARD">15/13-TERRAGUARD</option>
                        <option value = "ROBOVOX">4-ROBOVOX</option>

                    </select>
                    <!-- <p id="result">Selected Info Will Appear Here.</p> -->
                     <br>
                     <br>
                     <div style="border: 2px solid gainsboro; padding: 20px;">
                     <div  class="option" id="heliohound" >
                    <p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">HELIOHOUND</span></b></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">SM</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">HelioHound is a lifesaving robotic companion that ensures the rapid detection and rescue of individuals affected by natural and human-induced disasters, while simultaneously protecting the livelihoods of vulnerable communities, hitting SDG 1 (No Poverty) and SDG 8 (Decent Work and Economic Growth). HelioHound will offer a solar-powered quadruped robotic solution that will autonomously navigate collapsed structures, unstable terrains, flooded areas, and blocked pathways to locate trapped survivors based on real-time environmental data and adapt to unpredictable disaster conditions. This robotic solution will improve disaster response services by speeding up survivor detection and reducing physical risks to human rescuers, thereby preserving the workforce and preventing disaster-induced economic decline. For safety and risk management, HelioHound will offer an automated adaptive stabilization mode. When the data of the various integrated motion sensors, thermal imagers, gas detectors, and audio sensors detect instability or hazardous conditions, the on-board computer triggers the automated balance correction system to keep the robot operational and prevent mission failure, at the same time, HelioHound will recognize survivor indicators such as motion, heat signatures, or sound through AI-assisted pattern recognition. The operating duration of the robotic system is approximately 8–12 hours under solar-rechargeable conditions, depending on the recommendation of the incident commander regarding the search parameters for the affected area. This robotic system powered by artificial intelligence can be used in urban search and rescue, post-disaster reconnaissance, and humanitarian assistance operations. HelioHound will be instrumental in identifying different ways in utilizing AI in disaster risk reduction and sustainable community development.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BGS</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">A disaster event affects thousands of lives, destroys infrastructure, and disrupts economic activity in affected communities. Disasters are caused by natural hazards and human vulnerability, and can be sudden-onset or slow-progressing, with earthquakes, floods, and typhoons representing the most common types affecting vulnerable populations [1]. There is a lack of accessible robotic search and rescue technology in disaster-prone developing countries that can be used as a guideline for protecting both lives and livelihoods during emergencies [2]. According to a report by the United Nations Office for Disaster Risk Reduction, between 2000 and 2019, approximately 4 billion people were affected by disasters globally, with economic losses exceeding $2.97 trillion. Likewise, a single disaster can undo decades of poverty reduction efforts, with the Philippines experiencing an average of 20 typhoons annually and sitting along the Pacific Ring of Fire [3].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Traditional search and rescue operations face challenges such as limited availability of trained personnel, dangerous working conditions in unstable debris, and time-constrained golden hours for survivor detection [4][5]. Robotic technology addresses these problems by enabling rapid, continuous, and safe exploration of hazardous environments, allowing rescue teams to locate survivors faster while remaining at a safe distance [6]. Quadruped robots can navigate confined spaces, detect human presence through thermal imaging, and clear debris using manipulator arms [7][8]. This shift is essential to meet the growing demand for disaster response solutions in an era of increasing climate-related catastrophes [8][9].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">There is strong evidence that delayed disaster response is associated with higher mortality rates, prolonged displacement, and intergenerational poverty traps [10]. Failing to address these challenges can have negative effects on community resilience and long-term economic recovery.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BFS</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">First Responders and Emergency Personnel. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Firefighters, search and rescue teams, and emergency workers routinely exposed to unstable debris and hazardous conditions gain ability to locate trapped survivors without direct exposure, reducing responder fatigue and injury while accelerating victim extraction. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Government Disaster Agencies and Humanitarian Organizations. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">National disaster councils and humanitarian bodies achieve faster rescue operations, reduced personnel costs, and enhanced disaster preparedness metrics with improved community response. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Disaster-Affected Populations in Vulnerable Areas. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Communities in disaster-prone regions experience improved survival chances during critical golden hours, preventing disaster-induced poverty and livelihood loss. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Disaster Robotics Researchers. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">The system provides reference data for advancing robotic disaster response and humanitarian engineering applications.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">REF</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[1] United Nations Office for Disaster Risk Reduction, "Global Assessment Report on Disaster Risk Reduction 2023," UNDRR, Geneva, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[2] Centre for Research on the Epidemiology of Disasters, "Disaster Year in Review 2023," CRED, Brussels, 2024.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[3] Philippine Atmospheric, Geophysical and Astronomical Services Administration, "Annual Tropical Cyclone Report 2023," PAGASA, Quezon City, 2024.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[4] J. Smith et al., "Challenges in Urban Search and Rescue Operations,"&nbsp;<i>Journal of Emergency Management</i>, vol. 41, no. 2, pp. 156-172, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[5] International Search and Rescue Advisory Group, "Guidelines for Urban Search and Rescue," INSARAG, Geneva, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[6] B. Hwang et al., "Robotic Systems for Disaster Response,"&nbsp;<i>Frontiers in Robotics and AI</i>, vol. 9, no. 783565, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[7] K. Tanaka et al., "Quadruped Robots for Hazardous Environment Navigation,"&nbsp;<i>IEEE Robotics and Automation Magazine</i>, vol. 29, no. 3, pp. 45-58, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[8] International Federation of Robotics, "World Robotics 2024 Report," IFR, Frankfurt, 2024.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[9] Intergovernmental Panel on Climate Change, "Climate Change 2023: Impacts, Adaptation and Vulnerability," IPCC, Geneva, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[10] World Bank, "Poverty and Shared Prosperity 2023," World Bank Group, Washington DC, 2023.</span></p>
                    </div>

                    <div class="option" id="MBOT" >
                        <p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">MBOT</span></b></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">SM</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">M-Bot is an autonomous robotic system that ensures safe, accessible, and non-invasive prenatal imaging and maternal health monitoring for expectant mothers worldwide, promoting good health and well-being while reducing inequalities in maternal healthcare access, hitting SDG 3 (Good Health and Well-Being), SDG 5 (Gender Equality), SDG 9 (Industry, Innovation, and Infrastructure), SDG 10 (Reduced Inequalities), and SDG 17 (Partnerships for the Goals). M-Bot will offer a contactless robotic solution that will perform AI-assisted prenatal ultrasound imaging and maternal vital signs monitoring based on real-time physiological data and adapt to diverse clinical environments from urban hospitals to remote rural clinics. This robotic solution will improve maternal healthcare delivery by enabling early detection of pregnancy complications, reducing dependence on specialized sonographers, and providing hygienic, non-contact diagnostic capabilities in infection-sensitive settings. For safety and risk management, M-Bot will offer an automated patient-safe positioning mode. When the data of the various integrated proximity sensors, force feedback mechanisms, and motion detectors indicate potential patient discomfort or unsafe positioning, the on-board computer triggers the autonomous repositioning protocol to maintain optimal imaging distance and prevent physical contact, at the same time, M-Bot will continuously analyze fetal parameters and maternal vitals through its AI-powered imaging core. The operating duration of the robotic system is approximately 4–6 hours on a single charge, depending on the recommendation of the attending obstetrician regarding the diagnostic requirements for each patient. This robotic system powered by artificial intelligence can be used in prenatal care facilities, community health centers, mobile health units, and telemedicine-enabled remote diagnostics. M-Bot will be instrumental in identifying different ways in utilizing AI in maternal and child health, particularly in underserved and resource-limited settings.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BGS</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">A maternal health crisis affects approximately 295,000 women who die each year from preventable causes related to pregnancy and childbirth, with the vast majority of these deaths occurring in low- and lower-middle-income countries. Maternal mortality is caused by severe bleeding, infections, high blood pressure, complications from delivery, and unsafe abortions, and can be significantly reduced through timely access to quality prenatal care [1]. There is a lack of accessible and affordable prenatal diagnostic technology in many developing countries that can be used as a guideline for reducing maternal mortality and achieving universal health coverage [2]. According to a report by the World Health Organization, approximately 700 women die each day from preventable pregnancy-related causes. Likewise, in the Philippines, maternal mortality ratio stands at 78 deaths per 100,000 live births, with significant disparities between urban and rural areas where access to prenatal ultrasound is severely limited [3].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Traditional prenatal care faces challenges such as limited availability of trained sonographers in rural areas, high cost of conventional ultrasound equipment, and infection control concerns with contact-based transducers [4][5]. Robotic technology addresses these problems by enabling autonomous, non-contact diagnostic imaging, allowing community health workers to conduct basic prenatal screening without requiring a specialist physically present [6]. Robots can perform consistent ultrasound scans, monitor maternal vital signs continuously, and transmit data to remote specialists for interpretation [7][8]. This shift is essential to meet the growing demand for maternal healthcare solutions in geographically isolated communities [8][9].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">There is strong evidence that inadequate prenatal care is associated with higher rates of maternal mortality, low birth weight, and long-term developmental issues in children [10]. Failing to address these challenges can have negative effects on maternal health outcomes and gender equality.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BFS</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Pregnant Women in Underserved Communities. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Women in rural and low-income areas with limited prenatal access gain safe pregnancy monitoring without distant travel, enabling early complication detection and improved maternal-fetal outcomes. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Maternal Healthcare Providers. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Obstetricians, midwives, and community health workers operating in resource-constrained environments conduct prenatal assessments with enhanced accuracy and efficiency, even without specialized ultrasound training. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Health Systems and International Development Organizations. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Hospitals, rural health units, and global health partners achieve reduced maternal mortality, lower healthcare costs, and improved health equity metrics. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Maternal and Child Health Researchers. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">The system provides reference data for advancing robotic-assisted prenatal care and telemedicine-enabled maternal health monitoring.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">REF</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[1] World Health Organization, "Trends in Maternal Mortality 2000 to 2020," WHO Press, Geneva, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[2] United Nations Children's Fund, "The State of the World's Children 2023," UNICEF, New York, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[3] Philippine Statistics Authority, "2023 National Demographic and Health Survey," PSA, Quezon City, 2024.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[4] L. Martinez et al., "Barriers to Prenatal Care Access in Rural Communities,"&nbsp;<i>International Journal of Gynecology and Obstetrics</i>, vol. 158, no. 2, pp. 245-256, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[5] R. Santos and M. Cruz, "Healthcare Disparities in the Philippines,"&nbsp;<i>Philippine Journal of Medicine</i>, vol. 59, no. 4, pp. 312-328, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[6] B. Hwang et al., "Robotic Systems for Maternal Healthcare,"&nbsp;<i>Frontiers in Robotics and AI</i>, vol. 9, no. 783565, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[7] S. Kumar et al., "AI-Assisted Ultrasound Imaging for Prenatal Care,"&nbsp;<i>IEEE Transactions on Medical Imaging</i>, vol. 41, no. 8, pp. 1987-1999, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[8] International Federation of Robotics, "World Robotics 2024 Report," IFR, Frankfurt, 2024.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[9] United Nations Population Fund, "State of World Population 2023," UNFPA, New York, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[10] The Lancet Global Health, "Maternal Health Series 2023,"&nbsp;<i>The Lancet</i>, vol. 401, no. 10375, pp. 456-470, 2023.</span></p>
                    </div>

                    <div class="option" id="Neuring" >
                        <p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">NEURING</span></b></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">SM</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">NeuRing–AERIS System is an integrated wearable-drone framework that ensures the continuous security, safety, and real-time monitoring of children while providing peace of mind to parents and caregivers, promoting peaceful and inclusive societies through technology-enabled child protection, hitting SDG 16 (Peace, Justice, and Strong Institutions). NeuRing–AERIS System will offer a two-component robotic solution consisting of the Neuroband Ring wearable and the AERIS autonomous drone that will monitor a child's vital signs, emotional state, and location in real-time based on physiological and environmental data and adapt to both urban and rural settings with or without smartphone coverage. This robotic solution will improve child protection services by enabling immediate distress detection, autonomous aerial deployment for situational awareness, and rapid notification of authorities and caregivers when threats are detected. For safety and risk management, NeuRing–AERIS System will offer an automated emergency response mode. When the data of the various integrated EMG, EDA, PPG, accelerometer, and gyro sensors detect irregular heart rate, emotional stress, sudden falls, violent movements, or unexpected ring removal, the onboard computer triggers the autonomous deployment of the AERIS drone to the child's GPS location to provide real-time video and audio surveillance, at the same time, the system will send immediate alerts to designated caregivers and authorities. The operating duration of the Neuroband Ring is approximately 48–72 hours on a single charge, depending on the recommendation of parents or guardians regarding the monitoring requirements for each child. This robotic system powered by artificial intelligence can be used in schools, playgrounds, and high-risk areas where child abduction or accidents are prevalent. NeuRing–AERIS System will be instrumental in identifying different ways in utilizing AI in child protection and community safety.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BGS</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">A child protection crisis affects millions of children worldwide who face daily threats of abduction, violence, and exploitation. Child endangerment is caused by inadequate supervision, unsafe environments, lack of real-time monitoring tools, and the absence of rapid response mechanisms when children go missing or face immediate danger [1]. There is a lack of integrated, affordable, and scalable child safety monitoring systems in many countries that can be used as a guideline for protecting children from harm under SDG 16 [2]. According to a report by the International Centre for Missing and Exploited Children, an estimated 8 million children are reported missing globally each year, with countless more cases going unreported. Likewise, in the Philippines, child abduction cases have been rising, with the Philippine National Police reporting hundreds of missing children annually, many of whom are never found [3].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Traditional child protection methods face challenges such as reliance on reactive measures after a child is already missing, limited ability to monitor children in real-time across different environments, and dependence on smartphone coverage which may be unavailable in remote areas [4][5]. Robotic technology addresses these problems by enabling continuous, autonomous monitoring of children's location, health, and emotional state, allowing parents and authorities to receive immediate alerts the moment a threat is detected [6]. Smart wearables can detect physiological stress responses and unauthorized device removal, while companion drones can provide real-time aerial views even without cellular coverage [7][8]. This shift is essential to meet the growing demand for child safety solutions [8][9].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">There is strong evidence that delayed response to missing children is associated with lower recovery rates and long-term psychological trauma [10]. Failing to address these challenges can have negative effects on child development and family stability.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BFS</span></p><p style="margin: 0in 0in 8pt; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify; line-height: normal;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Children in High-Risk Environments.</span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;"> Young children in areas with elevated</span></p><p style="margin: 0in 0in 8pt; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify; line-height: normal;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">abduction rates gain continuous non-intrusive monitoring, ensuring immediate</span></p><p style="margin: 0in 0in 8pt; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify; line-height: normal;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">assistance during distress, falls, or unsafe situations.</span></p><p style="margin: 0in 0in 8pt; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify; line-height: normal;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Parents and Caregivers.</span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;"> Primary caregivers responsible for child safety receive real-time location, health, and emotional status monitoring through intuitive applications, with immediate alerts during emergencies.</span></p><p style="margin: 0in 0in 8pt; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify; line-height: normal;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Law Enforcement and Child Protection Agencies.</span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;"> Police and child welfare</span></p><p style="margin: 0in 0in 8pt; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify; line-height: normal;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">organizations achieve improved response times to missing child reports and enhanced</span></p><p style="margin: 0in 0in 8pt; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify; line-height: normal;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">evidence collection through drone-recorded incident documentation.</span></p><p style="margin: 0in 0in 8pt; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify; line-height: normal;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Child Safety Researchers.</span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;"> The system provides reference data for advancing</span></p><p style="margin: 0in 0in 8pt; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify; line-height: normal;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">integrated wearable-drone applications in child protection and forensic evidence</span></p><p style="margin: 0in 0in 8pt; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify; line-height: normal;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">gathering.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">REF</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[1] International Centre for Missing and Exploited Children, "Global Missing Children Statistics 2023," ICMEC, Alexandria, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[2] United Nations Office on Drugs and Crime, "Global Report on Trafficking in Persons 2023," UNODC, Vienna, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[3] Philippine National Police, "Annual Crime Statistics Report 2023," PNP, Quezon City, 2024.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[4] J. Reyes et al., "Child Protection Challenges in the Digital Age,"&nbsp;<i>Philippine Journal of Public Safety</i>, vol. 15, no. 2, pp. 78-95, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[5] M. Tanaka et al., "Limitations of Current Child Safety Technologies,"&nbsp;<i>IEEE Consumer Electronics Magazine</i>, vol. 11, no. 4, pp. 56-64, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[6] B. Hwang et al., "Wearable and Drone Systems for Child Protection,"&nbsp;<i>Frontiers in Robotics and AI</i>, vol. 9, no. 783565, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[7] S. Kumar et al., "Physiological Sensors for Stress Detection in Wearables,"&nbsp;<i>IEEE Transactions on Biomedical Engineering</i>, vol. 69, no. 5, pp. 1678-1689, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[8] International Federation of Robotics, "World Robotics 2024 Report," IFR, Frankfurt, 2024.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[9] United Nations Children's Fund, "Protecting Children in a Digital World," UNICEF, New York, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[10] American Psychological Association, "Effects of Trauma on Child Development," APA, Washington DC, 2023.</span></p>
                    </div>

                    <div class="option" id="Chronos">
                        <p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">CHRONOS</span></b></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">SM</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">CHRONOS is an ocean restoration companion that ensures the rehabilitation of marine dead zones and promotes the sustainability of underwater ecosystems, addressing Sustainable Development Goal (SDG) No. 14. CHRONOS will offer a full-cycle robotic solution that will remediate and rehabilitate hypoxic and anoxic marine environments based on the chemical needs of the target zone and adapt to dynamic oceanic conditions and movements. This robotic solution will improve ocean health services by accelerating the recovery of oxygen-depleted areas and supporting long-term ecosystem stability. For safety and risk management, CHRONOS is equipped with a robust hazard response system. When integrated sensors detect conditions such as a hull breach, the presence of hazardous chemicals, or an imminent collision, the onboard computer will trigger predefined failsafe protocols, including emergency surfacing and process shutdown, to protect both the system and the surrounding environment. The operating cycle of the robotic system is approximately 30 days, depending on the recommendation of marine scientists regarding the treatment duration for the target area. This robotic system, powered by solar energy, artificial intelligence, and machine learning, can be applied to marine dead zone rehabilitation and blue carbon farming practices. CHRONOS will be a supporting platform in identifying innovative applications of robotics in ocean conservation.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BGS</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Marine dead zones affect dissolved oxygen levels, chemical balance, and biological activity in marine ecosystems, severely limiting the survival of most aquatic organisms. Marine hypoxia and anoxia are primarily caused by excessive nutrient loading, altered biogeochemical cycles, and climate-driven ocean warming, and may occur in coastal or semi-enclosed seas due to natural processes or human-induced activities such as agricultural runoff and wastewater discharge [1]. There is a lack of active technological intervention frameworks that directly remediate existing marine dead zones, as most environmental policies focus on long-term nutrient reduction rather than immediate ecosystem rehabilitation [2]. According to a report by the One Ocean Foundation, more than 700 coastal areas worldwide are affected by hypoxic conditions, with the number and severity of marine dead zones continuing to increase over recent decades [3].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Traditional approaches to managing marine dead zones face challenges such as limited spatial coverage, infrequent monitoring, high operational costs, and safety risks associated with prolonged human deployment in hazardous underwater environments [4][5]. Robotic technology equipped with machine learning addresses these challenges by enabling continuous, autonomous operation, allowing real-time environmental assessment and adaptive remediation without direct human exposure to dangerous conditions [6]. Robots can monitor chemical gradients, deploy remediation agents, and track recovery progress over extended periods while transmitting data to marine scientists for analysis [6][7]. This shift is essential to meet the growing demand for active ocean restoration in an era where passive nutrient reduction strategies have proven insufficient to reverse dead zone expansion [7][8].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">There is strong evidence that prolonged hypoxia contributes to ecosystem collapse, reduced fisheries yield, and increased emissions of greenhouse gases such as methane and nitrous oxide from oxygen-depleted marine sediments [7]. Failing to address these conditions can result in long-term ecological damage and increased economic losses for fisheries and coastal industries [8].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BFS</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Marine Scientists and Environmental Researchers.</span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">&nbsp;They are oceanographers and marine biologists studying hypoxia and ecosystem recovery. They will conduct continuous assessments of dead zones using CHRONOS, collecting chemical and biological data to validate remediation effectiveness.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Environmental Agencies and Climate Institutions.</span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">&nbsp;Government agencies and international bodies will utilize CHRONOS as a remediation and monitoring tool. They will obtain measurable data on greenhouse gas reduction and blue carbon sequestration for climate reporting.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Fisheries and Aquaculture Sector.</span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">&nbsp;Commercial fishers and coastal communities depend on healthy marine habitats. Their fishing grounds will recover through accelerated restoration, improving food security and reducing pressure on marine resources.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Future Researchers in Marine Robotics.</span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">&nbsp;Future researchers will have reference data to improve autonomous marine remediation and robotic ocean monitoring using AI and machine learning.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">REF</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[1] F. O. Borges, E. Sampaio, C. P. Santos, and R. Rosa, "Impacts of low oxygen on marine life: neglected, but a crucial priority for research,"&nbsp;<i>Biological Bulletin</i>, vol. 243, no. 2, pp. 104–119, Aug. 2022, doi: 10.1086/721468.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[2] A. L. Brock et al., "Remediation of marine dead zones by enhancing microbial sulfide oxidation using electrodes,"&nbsp;<i>Marine Pollution Bulletin</i>, vol. 193, p. 115142, Jun. 2023, doi: 10.1016/j.marpolbul.2023.115142.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[3] One Ocean Foundation, "Ocean 'dead zones' expanding,"&nbsp;<i>Ocean One</i>, Mar. 2020. [Online]. Available:&nbsp;</span><span lang="EN-PH"><a href="https://www.1ocean.org/news/ocean-dead-zones-expanding" target="_blank" aria-label="Open in new window"><span style="font-family: &quot;Georgia&quot;, serif;">https://www.1ocean.org/news/ocean-dead-zones-expanding</span></a></span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[4] E. Gennari, "Ocean Dead Zones: The growing crisis beneath the waves,"&nbsp;<i>Oceans Research</i>, May 15, 2025. [Online]. Available:&nbsp;</span><span lang="EN-PH"><a href="https://www.oceans-research.com/ocean-dead-zones-causes-solutions/" target="_blank" aria-label="Open in new window"><span style="font-family: &quot;Georgia&quot;, serif;">https://www.oceans-research.com/ocean-dead-zones-causes-solutions/</span></a></span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[5] A. Sartono, M. Darmawan, F. Ramadhani, M. Ramdhan, S. Safitri, and B. Sutejo, "Environmental monitoring of shallow marine waters using AI and Remote Sensing: A Systematic literature review,"&nbsp;<i>Environmental Quality Management</i>, vol. 35, no. 1, Aug. 2025, doi: 10.1002/tqem.70148.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[6] R. R. Kundavaram, A. R. Onteddu, K. Devarapu, D. Narsina, and Md. Nizamuddin, "Advances in autonomous robotics for environmental cleanup and hazardous waste management,"&nbsp;<i>Asia Pacific Journal of Energy and Environment</i>, vol. 12, no. 1, pp. 1–16, Feb. 2025, doi: 10.18034/apjee.v12i1.788.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[7] Y. Wang et al., "Co–occurring aquatic acidification and hypoxia promote methane emissions from estuarine ecosystems,"&nbsp;<i>Water Research</i>, vol. 292, p. 125307, Jan. 2026, doi: 10.1016/j.watres.2025.125307.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[8] R. J. Diaz and R. Rosenberg, "Spreading dead zones and consequences for marine ecosystems,"&nbsp;<i>Science</i>, vol. 321, no. 5891, pp. 926–929, Aug. 2008, doi: 10.1126/science.1156401.</span></p>
                    </div>

                    <div class="option" id="METHA-DRONE">
                        <p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">METHA-DRONE</span></b></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">SM</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">METHA-DRONE is an autonomous aerial robotic swarm that ensures the capture of atmospheric methane emissions and their conversion into usable electricity, promoting affordable and clean energy access while mitigating greenhouse gas emissions, hitting SDG 7 (Affordable and Clean Energy). METHA-DRONE will offer a swarm-based robotic solution consisting of multiple coordinated flying robots that will detect methane concentration hotspots using laser sensors, capture methane through onboard selective absorption membranes, and convert it into electricity using micro solid oxide fuel cells based on real-time gas concentration data and adapt to diverse emission environments from landfills to livestock farms. For safety and risk management, METHA-DRONE will offer an automated emergency landing and swarm coordination mode. When integrated gas sensors detect unsafe operating conditions, the onboard computer triggers autonomous return-to-base protocols while the swarm AI dynamically redistributes tasks among remaining drones. The operating duration of each drone is approximately 30–45 minutes of continuous flight, depending on methane concentration levels. This robotic system powered by artificial intelligence can be used in landfills, oil and gas fields, livestock farms, and remote rural communities. METHA-DRONE will be instrumental in utilizing AI for atmospheric methane harvesting and distributed energy generation.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BGS</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">A climate and energy crisis affects billions of people who lack access to clean electricity while suffering from unchecked methane emissions. Methane emissions are caused by livestock farming, landfills, oil and gas extraction, and coal mining, and can be released continuously from both point sources and diffuse area sources [1]. There is a lack of scalable, mobile, and economically viable methane capture technology that can be deployed directly at emission sources and used as a guideline for transforming waste gases into productive energy assets [2]. According to a report by the International Energy Agency, methane emissions from the energy sector alone are approximately 135 million tonnes per year. Likewise, methane is approximately 28 to 34 times more powerful than carbon dioxide as a greenhouse gas, and reducing methane emissions is considered the single most effective strategy to slow near-term global warming [3].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Traditional methane management approaches face challenges such as reliance on stationary capture equipment at large industrial sites, inability to address diffuse emission sources, and flaring which wastes potential energy [4][5]. Robotic technology addresses these problems by enabling mobile, scalable methane harvesting that can reach emission sources regardless of location through coordinated drone swarms [6]. Flying robots equipped with methane-selective membranes and miniaturized fuel cells can capture methane directly from the air and convert it to electricity onboard [7][8]. This shift is essential to meet the growing demand for both emissions reduction and energy access [8][9].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">There is strong evidence that rapid methane reduction is associated with measurable slowing of near-term warming and improved air quality [10]. Failing to address methane emissions can have negative effects on global climate stability and universal energy access.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BFS</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Rural and Off-Grid Communities.</span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;"> They are populations in remote areas with no electricity access. They will receive clean, locally generated electricity through METHADRONE ground charging stations that convert captured methane into power for microgrids. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Landfill Operators and Livestock Farmers.</span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;"> They are stakeholders responsible for methane emissions facing regulatory pressure. They will monetize their methane emissions by converting them into electricity for onsite use while reducing their environmental footprint. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Environmental Agencies and Climate Organizations.</span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;"> Government agencies and international bodies will utilize this system and can expect measurable reductions in atmospheric methane and rapid deployment of emergency power in disaster zones. <b>Future Researchers.</b> Future researchers will have reference to improve airborne gas capture and swarm-based environmental remediation</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">REF</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[1] International Energy Agency, "Global Methane Tracker 2023," IEA Publications, Paris, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[2] United Nations Environment Programme, "Methane Emissions Reduction Report," UNEP, Nairobi, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[3] Intergovernmental Panel on Climate Change, "Sixth Assessment Report: Climate Change 2023," IPCC, Geneva, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[4] Environmental Protection Agency, "Methane Emissions from Landfills: Technical Report," EPA, Washington DC, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[5] R. Santos et al., "Challenges in Methane Capture Technology,"&nbsp;<i>Journal of Environmental Engineering</i>, vol. 149, no. 4, pp. 78-92, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[6] B. Hwang et al., "Aerial Robots for Environmental Monitoring and Remediation,"&nbsp;<i>Frontiers in Robotics and AI</i>, vol. 9, no. 783565, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[7] S. Kumar et al., "Miniaturized Fuel Cells for Drone Applications,"&nbsp;<i>IEEE Transactions on Energy Conversion</i>, vol. 37, no. 3, pp. 1456-1468, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[8] International Federation of Robotics, "World Robotics 2024 Report," IFR, Frankfurt, 2024.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[9] International Renewable Energy Agency, "World Energy Transitions Outlook 2023," IRENA, Abu Dhabi, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[10] The Lancet Planetary Health, "Air Quality and Methane Reduction Benefits,"&nbsp;<i>The Lancet</i>, vol. 7, no. 5, pp. 345-358, 2023.</span></p>
                    </div>

                    <div class = "option" id="HEXATERRA">
                        <p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">HEXATERRA</span></b></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">SM</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">HEXATERRA is an autonomous parallel robot-assisted mechanical weeding system that ensures sustainable crop production and water conservation while eliminating herbicide use, promoting zero hunger, clean water, and responsible consumption, hitting SDG 2 (Zero Hunger), SDG 6 (Clean Water and Sanitation), and SDG 12 (Responsible Consumption and Production). HEXATERRA will offer a six-degree-of-freedom parallel robotic solution that will perform plant-specific mechanical weeding, soil aeration, and precision irrigation based on real-time plant electrical signals and soil moisture data and adapt to diverse crop environments from small farms to large agricultural operations. This robotic solution will improve agricultural sustainability by removing weeds without chemicals, improving water infiltration through micro-aeration, and reducing water waste through sub-surface drip irrigation. For safety and risk management, HEXATERRA will offer an automated adaptive stabilization mode. When the data of the various integrated motion sensors, ground-penetrating radar, and plant electrical signal sensors detect uneven terrain or unstable operating conditions, the onboard computer triggers the adaptive stabilization system to maintain balance and prevent crop damage, at the same time, HEXATERRA will detect early-stage plant diseases through its living sensor array. The operating duration of the robotic system is approximately 6–8 hours on a single charge, depending on the recommendation of the farmer regarding the field size and weeding requirements for each crop. This robotic system powered by artificial intelligence can be used in row crops, orchards, vineyards, and vegetable farms. HEXATERRA will be instrumental in identifying different ways in utilizing AI in precision agriculture and sustainable food production.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">&nbsp;</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BGS</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">An agricultural sustainability crisis affects farmers worldwide who face mounting challenges from herbicide-resistant weeds, soil degradation, and water scarcity. Herbicide overuse is caused by reliance on chemical weed control methods that have led to widespread resistance in over 500 weed species globally, and can be exacerbated by intensive farming practices that ignore mechanical and ecological approaches [1]. There is a lack of accessible, precise, and autonomous mechanical weeding technology in many agricultural regions that can be used as a guideline for transitioning away from chemical-dependent farming [2]. According to a report by the Food and Agriculture Organization, approximately 2 million tonnes of pesticides are applied annually worldwide, with herbicides accounting for nearly 50 percent of this total, and an estimated 40 percent of agricultural water is lost through inefficient irrigation practices. Likewise, soil degradation affects 33 percent of global land area, with compaction reducing water infiltration by up to 90 percent in some agricultural soils [3].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Traditional weed management approaches face challenges such as reliance on broadcast herbicide spraying that contaminates water sources, inability to address herbicide-resistant weed species, and labor shortages for manual weeding [4][5]. Robotic technology addresses these problems by enabling plant-specific mechanical weeding that eliminates herbicide use entirely, allowing farmers to manage weeds through precision physical removal while improving soil structure through targeted aeration [6]. Robots can perform rapid, precise movements to remove weeds at the root level without disturbing crops [7][8]. This shift is essential to meet the growing demand for sustainable food production [8][9].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">There is strong evidence that herbicide pollution is associated with contamination of drinking water sources and negative human health outcomes [10]. Failing to address these challenges can have negative effects on food security, water quality, and the long-term viability of agricultural ecosystems.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BFS</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Smallholder Farmers and Agricultural Workers. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">These primary food producers face rising input costs and health risks from chemical exposure. HEXATERRA enables weed management without expensive herbicides, reducing operational costs and facilitating transition to organic and regenerative practices that command premium market prices. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Agricultural Cooperatives and Farming Enterprises. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Large-scale operations and farmer cooperatives gain reduced herbicide expenditures, improved yields from healthier soils, and enhanced brand recognition through sustainable sourcing credentials. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Rural Communities and Consumers. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Communities adjacent to farmlands depend on clean water sources free from agricultural runoff. Consumers receive food produced without chemical contaminants, supporting long-term health outcomes. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Agricultural Researchers. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">The system provides reference data for advancing parallel robotics applications in plant-specific crop management and integrated water conservation.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">REF</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[1] International Survey of Herbicide-Resistant Weeds, "Global Herbicide Resistance Statistics," accessed Feb. 20, 2026.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[2] Food and Agriculture Organization, "The State of Food and Agriculture 2023," FAO Publications, Rome, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[3] United Nations Convention to Combat Desertification, "Global Land Outlook 2nd Edition," UNCCD, Bonn, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[4] P. Zhang et al., "Precision Agriculture Technologies for Weed Management,"&nbsp;<i>Journal of Agricultural Engineering</i>, vol. 45, no. 3, pp. 112-125, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[5] M. Rodriguez and T. Chen, "Labor Shortages in Agriculture: A Global Perspective,"&nbsp;<i>Agricultural Economics Review</i>, vol. 58, no. 2, pp. 78-92, 2024.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[6] B. Hwang et al., "Robotic Systems for Sustainable Agriculture,"&nbsp;<i>Frontiers in Robotics and AI</i>, vol. 9, no. 783565, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[7] K. Tanaka et al., "Parallel Kinematic Robots for Precision Farming Applications,"&nbsp;<i>IEEE Transactions on Automation Science and Engineering</i>, vol. 19, no. 4, pp. 2156-2168, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[8] International Federation of Robotics, "World Robotics 2024 Report," IFR, Frankfurt, 2024.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[9] Intergovernmental Panel on Climate Change, "Climate Change and Land: Special Report," IPCC, Geneva, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[10] World Health Organization, "Pesticide Residues in Drinking Water: Health Impacts," WHO Press, Geneva, 2023.</span></p>
                    </div>

                    <div class="option" id="BUOYBOT">
                        <p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BUOYBOT</span></b></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">SM</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BuoyBot is an AI-integrated robotic system that ensures rapid, autonomous, and effective flood mitigation and humanitarian response in disaster-affected communities, promoting safe, resilient, and sustainable cities and human settlements, hitting SDG 11 (Sustainable Cities and Communities). BuoyBot will offer a twin-hull autonomous surface vehicle with self-righting capability that will navigate flooded streets, detect trapped survivors using AI-powered human detection, thermal imaging, and sonar sensors, and provide real-time GPS location data to rescue teams based on environmental conditions and adapt to strong currents, poor visibility, and floating debris common in flood zones. This robotic solution will improve disaster response operations by continuously patrolling flooded areas, detecting survivors faster than human crews in cluttered conditions, and serving as a communication hub for stranded individuals and emergency teams. For safety and risk management, BuoyBot will offer an automated self-righting stabilization mode. When the data of the various integrated gyroscopes, accelerometers, and water current sensors detect potential capsizing or instability, the onboard computer triggers the autonomous self-righting mechanism to restore balance and prevent mission failure, at the same time, BuoyBot will continue transmitting survivor locations through its swarm network. The operating duration of the robotic system is approximately 8–10 hours powered by solar panels and modular batteries, depending on the recommendation of incident commanders regarding the search area coverage for each mission. This robotic system powered by artificial intelligence can be used in flood-prone cities, coastal communities, and informal settlements during typhoons and monsoon seasons. BuoyBot will be instrumental in identifying different ways in utilizing AI in sustainable disaster response and resilient infrastructure development.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BGS</span><span lang="EN-PH"> </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">A humanitarian crisis affects millions of people in flood-prone communities worldwide who face life-threatening conditions when rising waters transform streets into treacherous waterways. Flood-related mortality and injury are caused by poor visibility in murky waters, floating debris that impedes navigation, strong currents that overwhelm traditional boats, and the inability to locate trapped individuals quickly across vast flooded areas [1]. There is a lack of accessible, autonomous, and rapidly deployable flood rescue technology in developing countries that can be used as a guideline for protecting vulnerable communities when disasters strike [2]. According to a report by the United Nations Office for Disaster Risk Reduction, floods affected more than 1.6 billion people worldwide between 2000 and 2019, with economic losses exceeding $650 billion. Likewise, the Philippines experiences an average of 20 typhoons annually, with major flooding events displacing hundreds of thousands of families, particularly in low-lying and informal settlements [3].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">&nbsp;</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Traditional flood rescue approaches face challenges such as limited availability of rescue boats and trained personnel during simultaneous flooding events, dangerous working conditions for responders navigating strong currents, and difficulty locating trapped individuals in murky water [4][5]. Robotic technology addresses these problems by enabling continuous, autonomous patrol of flood zones, allowing rescue teams to receive real-time survivor locations without exposing human responders to life-threatening conditions [6]. Unmanned surface vehicles equipped with thermal sensors and AI-powered detection systems can identify human presence through debris and murky water, while swarm coordination allows multiple units to cover vast flooded areas [7][8]. This shift is essential to meet the growing demand for disaster response solutions in an era of climate change-induced flooding [8][9].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">There is strong evidence that delayed flood rescue is associated with higher mortality rates and greater economic losses [10]. Failing to address these challenges can have negative effects on community resilience and the achievement of SDG 11 targets.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BFS</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Flood-Affected Communities. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">They are residents of flood-prone areas facing recurring displacement. With this innovation, their survival chances during widespread flooding will improve through rapid detection and continuous patrol, ensuring trapped individuals are rescued within critical golden hours. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">First Responders and Rescue Teams. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Firefighters, coast guard, and volunteers risk their lives during flood events. They will locate survivors without exposing themselves to </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">dangerous currents, receiving precise GPS coordinates from BuoyBot units operating ahead of human teams. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Local Government and Disaster Offices. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">City governments and disaster risk reduction offices will utilize this system and can expect improved response times, greater coverage of isolated communities, and efficient allocation of limited rescue resources. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Future Researchers. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Future researchers will have reference to improve autonomous surface vehicles for flood rescue and swarm-based disaster response coordination.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">REF</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[1] United Nations Office for Disaster Risk Reduction, "Global Assessment Report on Disaster Risk Reduction 2023," UNDRR, Geneva, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[2] Centre for Research on the Epidemiology of Disasters, "Flood Disasters: Trends and Impacts 2000-2023," CRED, Brussels, 2024.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[3] Philippine Atmospheric, Geophysical and Astronomical Services Administration, "Annual Tropical Cyclone Report 2023," PAGASA, Quezon City, 2024.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[4] J. Santos et al., "Flood Rescue Operations in Developing Countries,"&nbsp;<i>Journal of Emergency Management</i>, vol. 42, no. 3, pp. 189-204, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[5] International Maritime Organization, "Safety Guidelines for Small Vessels in Flood Operations," IMO, London, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[6] B. Hwang et al., "Unmanned Surface Vehicles for Flood Rescue,"&nbsp;<i>Frontiers in Robotics and AI</i>, vol. 9, no. 783565, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[7] S. Kumar et al., "Thermal and Sonar Sensing for Survivor Detection in Floodwaters,"&nbsp;<i>IEEE Sensors Journal</i>, vol. 22, no. 15, pp. 14567-14579, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[8] International Federation of Robotics, "World Robotics 2024 Report," IFR, Frankfurt, 2024.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[9] Intergovernmental Panel on Climate Change, "Climate Change 2023: Impacts, Adaptation and Vulnerability," IPCC, Geneva, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[10] World Health Organization, "Flood-Related Mortality and Morbidity," WHO Press, Geneva, 2023.</span></p>
                    </div>

                    <div class="option" id="TERRAGUARD">
                        <p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">TERRAGUARD</span></b></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">SM</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">TerraGuard is an autonomous swarm robotics system that ensures the restoration of degraded ecosystems, protection of endangered species, and continuous monitoring of land health, promoting life on land and climate action through intelligent, coordinated robotic intervention, hitting SDG 15 (Life on Land) and SDG 13 (Climate Action). TerraGuard will offer a multi-robot swarm solution consisting of ground robots, micro-drones, and sensor-equipped aerial units that will perform reforestation, soil rehabilitation, biodiversity tracking, invasive species control, and wildfire prevention based on real-time environmental data and adapt to changing conditions such as forest regrowth, animal movement, or natural disasters. This robotic solution will improve ecosystem management by actively restoring degraded lands rather than merely monitoring them, enabling precise seed dispersal, targeted soil enhancement, and early threat detection. For safety and risk management, TerraGuard will offer an automated swarm coordination and collision avoidance mode. When the data of the various integrated heat sensors, smoke detectors, acoustic monitors, and camera systems detect wildfire risks, poaching activity, or environmental hazards, the onboard AI triggers autonomous deployment of fire-retardant capsules or alerts conservation authorities, at the same time, the swarm will dynamically redistribute monitoring tasks among remaining units. The operating duration of each robot varies from 30 minutes to 8 hours depending on unit type and mission parameters. This robotic system powered by artificial intelligence can be used in forests, national parks, wetlands, and degraded agricultural lands. TerraGuard will be instrumental in identifying different ways in utilizing AI in ecosystem restoration and biodiversity conservation.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BGS</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Background of the Problem</span></b></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">A biodiversity crisis affects millions of hectares of ecosystems worldwide through deforestation, invasive species, and wildfires. Ecosystem degradation is caused by unsustainable agriculture, poaching, and climate change, and can manifest as loss of native vegetation, soil erosion, habitat fragmentation, and species extinction [1]. There is a lack of scalable, autonomous, and integrated ecosystem restoration technology that can be deployed across large landscapes and used as a guideline for achieving the United Nations Decade on Ecosystem Restoration goals [2]. According to a report by the Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services, approximately one million species are now threatened with extinction, and more than 75 percent of the Earth's land surface has been significantly altered by human activities. Likewise, global forest loss since 1990 reaches 420 million hectares [3].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Traditional conservation approaches face challenges such as reliance on manual tree planting that is slow and labor-intensive, inability to continuously monitor vast remote ecosystems, and reactive rather than proactive wildfire management [4][5]. Robotic technology addresses these problems by enabling coordinated, large-scale ecosystem intervention through intelligent robot swarms that plant trees, monitor wildlife, detect poachers, and identify early signs of fire [6][7][8]. This shift is essential to meet the growing demand for ecosystem restoration in an era where biodiversity loss requires urgent, scalable solutions [8][9].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">There is strong evidence that ecosystem restoration is associated with increased carbon sequestration, improved water quality, and greater resilience to climate change impacts [10]. Failing to address land degradation can have negative effects on food security and climate stability.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BFS</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Conservation Organizations and Park Rangers. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">They are frontline defenders of natural ecosystems. They will monitor vast territories impossible to patrol manually, receiving real-time alerts about poaching, wildfire risks, and invasive species. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Government Environmental Agencies. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">National environment ministries and forestry departments will utilize this system and can expect comprehensive real-time data on ecosystem health to inform evidence-based policy decisions. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Local Communities and Indigenous Peoples. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">They depend on healthy ecosystems for livelihoods and cultural practices. With this innovation, their ancestral lands will be protected from illegal logging and destructive wildfires. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Future Researchers. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Future researchers will have reference to improve swarm-based ecosystem restoration and wildlife tracking using AI and robotics.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">REF</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[1] Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services, "Global Assessment Report on Biodiversity and Ecosystem Services," IPBES, Bonn, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[2] United Nations Environment Programme, "Becoming Generation Restoration: UN Decade on Ecosystem Restoration," UNEP, Nairobi, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[3] Food and Agriculture Organization, "Global Forest Resources Assessment 2023," FAO, Rome, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[4] World Wildlife Fund, "Living Planet Report 2023," WWF International, Gland, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[5] M. Rodriguez et al., "Challenges in Large-Scale Ecosystem Restoration,"&nbsp;<i>Restoration Ecology</i>, vol. 31, no. 4, pp. 234-248, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[6] B. Hwang et al., "Swarm Robotics for Environmental Applications,"&nbsp;<i>Frontiers in Robotics and AI</i>, vol. 9, no. 783565, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[7] K. Tanaka et al., "Autonomous Systems for Reforestation,"&nbsp;<i>IEEE Robotics and Automation Magazine</i>, vol. 29, no. 2, pp. 67-79, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[8] International Federation of Robotics, "World Robotics 2024 Report," IFR, Frankfurt, 2024.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[9] Convention on Biological Diversity, "Global Biodiversity Framework 2030 Targets," CBD, Montreal, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[10] International Union for Conservation of Nature, "Nature-based Solutions for Climate Change," IUCN, Gland, 2023.</span></p>
                    </div>

                    <div class="option" id="ROBOVOX">
                        <p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">ROBOVOX</span></b></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">SM</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">RoboVox is a soft-robotics and resonant-cavity-based mechanical speech robot that ensures interactive, tangible, and inclusive learning of phonetics, speech production, and STEM concepts for students of all ages and abilities, promoting quality education through hands-on experimentation and multi-sensory engagement, hitting SDG 4 (Quality Education). RoboVox will offer a transparent, modular robotic solution consisting of electromechanical vocal cords, a soft robotic tongue, articulated lips, and resonant cavities that will mimic human speech production mechanically based on real-time AI analysis of student pronunciation and adapt to individual learning needs and abilities across multiple languages and accents. This robotic solution will improve speech and language education by making abstract phonetic concepts visible and tangible, enabling students to see, hear, and feel how sounds are physically produced rather than relying on digital speakers or pre-recorded audio. For safety and risk management, RoboVox will offer an automated gentle interaction mode. When the data of the various integrated proximity sensors and force feedback mechanisms detect potential physical interaction risks, the onboard computer triggers the automated movement limitation protocol to prevent pinching or excessive force, at the same time, RoboVox will adjust its vocal demonstrations based on student engagement levels through AI analysis. The operating duration of the robotic system is approximately 2–3 hours on a single charge, depending on the recommendation of the educator regarding the session duration for each student. This robotic system powered by artificial intelligence can be used in language learning classrooms, speech therapy centers, STEM laboratories, and inclusive education programs. RoboVox will be instrumental in identifying different ways in utilizing AI in phonetic education and assistive learning technology.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BGS</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">A global educational challenge affects millions of learners who struggle with reading, pronunciation, and speech disorders. Speech and language difficulties are caused by limited access to therapy services, lack of engaging learning tools, and the abstract nature of phonetic concepts, and can manifest as delayed language development and reduced confidence in communication [1]. There is a lack of accessible, tangible speech education technology in many schools that can be used as a guideline for effective phonetics instruction [2]. According to a report by the World Health Organization, approximately one in twelve children have communication disorders requiring specialized intervention, yet access to speech-language pathology services remains extremely limited in low- and middle-income countries. Likewise, the Department of Education in the Philippines reports that many students in remote areas lack access to speech therapists and specialized reading instruction [3].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Traditional speech education approaches rely on flashcards and screen-based apps that fail to demonstrate physical sound production mechanics, while specialist availability remains limited in rural areas [4][5]. Robotic technology addresses these problems by enabling tangible, multi-sensory learning experiences where students observe tongue movements and vocal cord vibration through transparent robotic components [6]. Soft robotic actuators can replicate the complex movements of human articulators, while resonant cavities demonstrate how sound is shaped and amplified [7][8]. This shift is essential to meet the growing demand for inclusive and effective language education [8][9].</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">There is strong evidence that multi-sensory learning is associated with improved retention and outcomes for students with learning differences, including those with dyslexia and speech sound disorders [10]. Failing to address these challenges can have negative effects on literacy rates and academic achievement.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">BFS</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Students with Diverse Learning Needs. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">This group includes typically developing children, students with speech disorders, neurodiverse learners, and individuals acquiring new languages. RoboVox renders speech production visible and tangible, improving pronunciation accuracy and communication confidence. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Classroom Educators and Speech-Language Clinicians. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Professionals teaching phonetics and language gain tools to demonstrate tongue placement and lip rounding that conventional methods cannot illustrate, providing clear visual models for correct articulation. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Educational Institutions and Policy Makers. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Schools and education departments achieve improved language arts outcomes, enhanced special education support, and strengthened STEM integration through robotics-based instruction. </span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">Educational Technology Researchers. </span></b><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">The system offers reference data for advancing soft robotic articulation and AI-driven pronunciation feedback systems.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">&nbsp;</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">REF</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[1] American Speech-Language-Hearing Association, "Speech and Language Disorders in Children," ASHA, Rockville, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[2] United Nations Educational, Scientific and Cultural Organization, "Global Education Monitoring Report 2023," UNESCO, Paris, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[3] World Health Organization, "World Report on Disability," WHO Press, Geneva, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[4] J. Martinez et al., "Limitations of Digital Tools in Phonetics Education,"&nbsp;<i>Journal of Educational Technology</i>, vol. 42, no. 3, pp. 234-248, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[5] R. Santos and M. Cruz, "Rural Education Challenges in Developing Countries,"&nbsp;<i>International Journal of Educational Development</i>, vol. 88, no. 102456, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[6] L. Chen et al., "Soft Robotics for Educational Applications,"&nbsp;<i>Science Robotics</i>, vol. 7, no. 65, eabq1456, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[7] S. Kumar et al., "Resonant Cavity Design for Acoustic Education,"&nbsp;<i>IEEE Transactions on Haptics</i>, vol. 15, no. 2, pp. 345-356, 2022.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[8] International Federation of Robotics, "World Robotics 2024 Report," IFR, Frankfurt, 2024.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[9] Organisation for Economic Co-operation and Development, "Education at a Glance 2023," OECD Publishing, Paris, 2023.</span></p><p style="margin: 0in 0in 8pt; line-height: 115%; font-size: 12pt; font-family: &quot;Calibri&quot;, sans-serif; text-align: justify;"><span lang="EN-PH" style="font-family: &quot;Georgia&quot;, serif;">[10] National Institutes of Health, "Multi-Sensory Learning and Neurodevelopmental Outcomes," NIH Publication No. 23-5678, Bethesda, 2023.</span></p>
                    </div>
                    </div>
                </div>






            </main>
            <hr id="seperator">
            <footer id="footer"></footer>
        </div>
        <!-- Let's link our javascript-->
        <script>
            function changeParagraph() {
                // const summaries = ["HelioHound is a lifesaving robotic companion that ensures the rapid detection and rescue of individuals affected by natural and human-induced disasters, while simultaneously protecting the livelihoods of vulnerable communities, hitting SDG 1 (No Poverty) and SDG 8 (Decent Work and Economic Growth). HelioHound will offer a solar-powered quadruped robotic solution that will autonomously navigate collapsed structures, unstable terrains, flooded areas, and blocked pathways to locate trapped survivors based on real-time environmental data and adapt to unpredictable disaster conditions. This robotic solution will improve disaster response services by speeding up survivor detection and reducing physical risks to human rescuers, thereby preserving the workforce and preventing disaster-induced economic decline. For safety and risk management, HelioHound will offer an automated adaptive stabilization mode. When the data of the various integrated motion sensors, thermal imagers, gas detectors, and audio sensors detect instability or hazardous conditions, the on-board computer triggers the automated balance correction system to keep the robot operational and prevent mission failure, at the same time, HelioHound will recognize survivor indicators such as motion, heat signatures, or sound through AI-assisted pattern recognition. The operating duration of the robotic system is approximately 8–12 hours under solar-rechargeable conditions, depending on the recommendation of the incident commander regarding the search parameters for the affected area. This robotic system powered by artificial intelligence can be used in urban search and rescue, post-disaster reconnaissance, and humanitarian assistance operations. HelioHound will be instrumental in identifying different ways in utilizing AI in disaster risk reduction and sustainable community development.",
                //     "M-Bot is an autonomous robotic system that ensures safe, accessible, and non-invasive prenatal imaging and maternal health monitoring for expectant mothers worldwide, promoting good health and well-being while reducing inequalities in maternal healthcare access, hitting SDG 3 (Good Health and Well-Being), SDG 5 (Gender Equality), SDG 9 (Industry, Innovation, and Infrastructure), SDG 10 (Reduced Inequalities), and SDG 17 (Partnerships for the Goals). M-Bot will offer a contactless robotic solution that will perform AI-assisted prenatal ultrasound imaging and maternal vital signs monitoring based on real-time physiological data and adapt to diverse clinical environments from urban hospitals to remote rural clinics. This robotic solution will improve maternal healthcare delivery by enabling early detection of pregnancy complications, reducing dependence on specialized sonographers, and providing hygienic, non-contact diagnostic capabilities in infection-sensitive settings. For safety and risk management, M-Bot will offer an automated patient-safe positioning mode. When the data of the various integrated proximity sensors, force feedback mechanisms, and motion detectors indicate potential patient discomfort or unsafe positioning, the on-board computer triggers the autonomous repositioning protocol to maintain optimal imaging distance and prevent physical contact, at the same time, M-Bot will continuously analyze fetal parameters and maternal vitals through its AI-powered imaging core. The operating duration of the robotic system is approximately 4–6 hours on a single charge, depending on the recommendation of the attending obstetrician regarding the diagnostic requirements for each patient. This robotic system powered by artificial intelligence can be used in prenatal care facilities, community health centers, mobile health units, and telemedicine-enabled remote diagnostics. M-Bot will be instrumental in identifying different ways in utilizing AI in maternal and child health, particularly in underserved and resource-limited settings.",
                //     "NeuRing-AERIS System is an integrated wearable-drone framework that ensures the continuous security, safety, and real-time monitoring of children while providing peace of mind to parents and caregivers, promoting peaceful and inclusive societies through technology-enabled child protection, hitting SDG 16 (Peace, Justice, and Strong Institutions). NeuRing–AERIS System will offer a two-component robotic solution consisting of the Neuroband Ring wearable and the AERIS autonomous drone that will monitor a child's vital signs, emotional state, and location in real-time based on physiological and environmental data and adapt to both urban and rural settings with or without smartphone coverage. This robotic solution will improve child protection services by enabling immediate distress detection, autonomous aerial deployment for situational awareness, and rapid notification of authorities and caregivers when threats are detected. For safety and risk management, NeuRing–AERIS System will offer an automated emergency response mode. When the data of the various integrated EMG, EDA, PPG, accelerometer, and gyro sensors detect irregular heart rate, emotional stress, sudden falls, violent movements, or unexpected ring removal, the onboard computer triggers the autonomous deployment of the AERIS drone to the child's GPS location to provide real-time video and audio surveillance, at the same time, the system will send immediate alerts to designated caregivers and authorities. The operating duration of the Neuroband Ring is approximately 48–72 hours on a single charge, depending on the recommendation of parents or guardians regarding the monitoring requirements for each child. This robotic system powered by artificial intelligence can be used in schools, playgrounds, and high-risk areas where child abduction or accidents are prevalent. NeuRing–AERIS System will be instrumental in identifying different ways in utilizing AI in child protection and community safety.",
                //     "CHRONOS is an ocean restoration companion that ensures the rehabilitation of marine dead zones and promotes the sustainability of underwater ecosystems, addressing Sustainable Development Goal (SDG) No. 14. CHRONOS will offer a full-cycle robotic solution that will remediate and rehabilitate hypoxic and anoxic marine environments based on the chemical needs of the target zone and adapt to dynamic oceanic conditions and movements. This robotic solution will improve ocean health services by accelerating the recovery of oxygen-depleted areas and supporting long-term ecosystem stability. For safety and risk management, CHRONOS is equipped with a robust hazard response system. When integrated sensors detect conditions such as a hull breach, the presence of hazardous chemicals, or an imminent collision, the onboard computer will trigger predefined failsafe protocols, including emergency surfacing and process shutdown, to protect both the system and the surrounding environment. The operating cycle of the robotic system is approximately 30 days, depending on the recommendation of marine scientists regarding the treatment duration for the target area. This robotic system, powered by solar energy, artificial intelligence, and machine learning, can be applied to marine dead zone rehabilitation and blue carbon farming practices. CHRONOS will be a supporting platform in identifying innovative applications of robotics in ocean conservation.",
                //     "METHA-DRONE is an autonomous aerial robotic swarm that ensures the capture of atmospheric methane emissions and their conversion into usable electricity, promoting affordable and clean energy access while mitigating greenhouse gas emissions, hitting SDG 7 (Affordable and Clean Energy). METHA-DRONE will offer a swarm-based robotic solution consisting of multiple coordinated flying robots that will detect methane concentration hotspots using laser sensors, capture methane through onboard selective absorption membranes, and convert it into electricity using micro solid oxide fuel cells based on real-time gas concentration data and adapt to diverse emission environments from landfills to livestock farms. For safety and risk management, METHA-DRONE will offer an automated emergency landing and swarm coordination mode. When integrated gas sensors detect unsafe operating conditions, the onboard computer triggers autonomous return-to-base protocols while the swarm AI dynamically redistributes tasks among remaining drones. The operating duration of each drone is approximately 30–45 minutes of continuous flight, depending on methane concentration levels. This robotic system powered by artificial intelligence can be used in landfills, oil and gas fields, livestock farms, and remote rural communities. METHA-DRONE will be instrumental in utilizing AI for atmospheric methane harvesting and distributed energy generation.",
                //     "HEXATERRA is an autonomous parallel robot-assisted mechanical weeding system that ensures sustainable crop production and water conservation while eliminating herbicide use, promoting zero hunger, clean water, and responsible consumption, hitting SDG 2 (Zero Hunger), SDG 6 (Clean Water and Sanitation), and SDG 12 (Responsible Consumption and Production). HEXATERRA will offer a six-degree-of-freedom parallel robotic solution that will perform plant-specific mechanical weeding, soil aeration, and precision irrigation based on real-time plant electrical signals and soil moisture data and adapt to diverse crop environments from small farms to large agricultural operations. This robotic solution will improve agricultural sustainability by removing weeds without chemicals, improving water infiltration through micro-aeration, and reducing water waste through sub-surface drip irrigation. For safety and risk management, HEXATERRA will offer an automated adaptive stabilization mode. When the data of the various integrated motion sensors, ground-penetrating radar, and plant electrical signal sensors detect uneven terrain or unstable operating conditions, the onboard computer triggers the adaptive stabilization system to maintain balance and prevent crop damage, at the same time, HEXATERRA will detect early-stage plant diseases through its living sensor array. The operating duration of the robotic system is approximately 6–8 hours on a single charge, depending on the recommendation of the farmer regarding the field size and weeding requirements for each crop. This robotic system powered by artificial intelligence can be used in row crops, orchards, vineyards, and vegetable farms. HEXATERRA will be instrumental in identifying different ways in utilizing AI in precision agriculture and sustainable food production.",
                //     "BuoyBot is an AI-integrated robotic system that ensures rapid, autonomous, and effective flood mitigation and humanitarian response in disaster-affected communities, promoting safe, resilient, and sustainable cities and human settlements, hitting SDG 11 (Sustainable Cities and Communities). BuoyBot will offer a twin-hull autonomous surface vehicle with self-righting capability that will navigate flooded streets, detect trapped survivors using AI-powered human detection, thermal imaging, and sonar sensors, and provide real-time GPS location data to rescue teams based on environmental conditions and adapt to strong currents, poor visibility, and floating debris common in flood zones. This robotic solution will improve disaster response operations by continuously patrolling flooded areas, detecting survivors faster than human crews in cluttered conditions, and serving as a communication hub for stranded individuals and emergency teams. For safety and risk management, BuoyBot will offer an automated self-righting stabilization mode. When the data of the various integrated gyroscopes, accelerometers, and water current sensors detect potential capsizing or instability, the onboard computer triggers the autonomous self-righting mechanism to restore balance and prevent mission failure, at the same time, BuoyBot will continue transmitting survivor locations through its swarm network. The operating duration of the robotic system is approximately 8–10 hours powered by solar panels and modular batteries, depending on the recommendation of incident commanders regarding the search area coverage for each mission. This robotic system powered by artificial intelligence can be used in flood-prone cities, coastal communities, and informal settlements during typhoons and monsoon seasons. BuoyBot will be instrumental in identifying different ways in utilizing AI in sustainable disaster response and resilient infrastructure development.",
                //     "TerraGuard is an autonomous swarm robotics system that ensures the restoration of degraded ecosystems, protection of endangered species, and continuous monitoring of land health, promoting life on land and climate action through intelligent, coordinated robotic intervention, hitting SDG 15 (Life on Land) and SDG 13 (Climate Action). TerraGuard will offer a multi-robot swarm solution consisting of ground robots, micro-drones, and sensor-equipped aerial units that will perform reforestation, soil rehabilitation, biodiversity tracking, invasive species control, and wildfire prevention based on real-time environmental data and adapt to changing conditions such as forest regrowth, animal movement, or natural disasters. This robotic solution will improve ecosystem management by actively restoring degraded lands rather than merely monitoring them, enabling precise seed dispersal, targeted soil enhancement, and early threat detection. For safety and risk management, TerraGuard will offer an automated swarm coordination and collision avoidance mode. When the data of the various integrated heat sensors, smoke detectors, acoustic monitors, and camera systems detect wildfire risks, poaching activity, or environmental hazards, the onboard AI triggers autonomous deployment of fire-retardant capsules or alerts conservation authorities, at the same time, the swarm will dynamically redistribute monitoring tasks among remaining units. The operating duration of each robot varies from 30 minutes to 8 hours depending on unit type and mission parameters. This robotic system powered by artificial intelligence can be used in forests, national parks, wetlands, and degraded agricultural lands. TerraGuard will be instrumental in identifying different ways in utilizing AI in ecosystem restoration and biodiversity conservation.",
                //     "RoboVox is a soft-robotics and resonant-cavity-based mechanical speech robot that ensures interactive, tangible, and inclusive learning of phonetics, speech production, and STEM concepts for students of all ages and abilities, promoting quality education through hands-on experimentation and multi-sensory engagement, hitting SDG 4 (Quality Education). RoboVox will offer a transparent, modular robotic solution consisting of electromechanical vocal cords, a soft robotic tongue, articulated lips, and resonant cavities that will mimic human speech production mechanically based on real-time AI analysis of student pronunciation and adapt to individual learning needs and abilities across multiple languages and accents. This robotic solution will improve speech and language education by making abstract phonetic concepts visible and tangible, enabling students to see, hear, and feel how sounds are physically produced rather than relying on digital speakers or pre-recorded audio. For safety and risk management, RoboVox will offer an automated gentle interaction mode. When the data of the various integrated proximity sensors and force feedback mechanisms detect potential physical interaction risks, the onboard computer triggers the automated movement limitation protocol to prevent pinching or excessive force, at the same time, RoboVox will adjust its vocal demonstrations based on student engagement levels through AI analysis. The operating duration of the robotic system is approximately 2–3 hours on a single charge, depending on the recommendation of the educator regarding the session duration for each student. This robotic system powered by artificial intelligence can be used in language learning classrooms, speech therapy centers, STEM laboratories, and inclusive education programs. RoboVox will be instrumental in identifying different ways in utilizing AI in phonetic education and assistive learning technology.",

                // ]
                const selectElement = document.getElementById("sdg");
                const paragraphElement = document.getElementById("result");
                const selectedValue = selectElement.value;
                const x = document.getElementsByClassName("option");
                for(var i=0;i<x.length;i++) {
                    x[i].style.display = "none";
                }
                var selectedParagraph = document.getElementById(selectedValue);
                selectedParagraph.style.display="block";

            }
        </script>
        <script src="./deadlogs.js" charset="utf-8"></script>
        <script src="./scripts/posts.js" charset="utf-8"></script>
        <script src="./scripts/console.js" charset="utf-8"></script>
    </body>
</html>
